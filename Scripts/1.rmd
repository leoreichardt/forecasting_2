---
title: "Exploratory analysis"
date: "4/20/2020"
output: html_document
---

```{r setup, include=FALSE}
library(hts)
library(stringi)
library(dplyr)
library(stringr)
library(purrr)
library(tidyr)
library(lubridate)
library(knitr)
library(ggplot2)
library(kableExtra)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# Load data
df <- read.csv('~/Documents/GitHub/forecasting_2/Data/sales_train_validation.csv', stringsAsFactors = FALSE)

df <- within(df, 
             item_id <- as.factor(item_id),
             dept_id <- as.factor(dept_id),
             cat_id <- as.factor(cat_id))

cal <- read.csv('~/Documents/GitHub/forecasting_2/Data/calendar.csv', na.strings = "")

prices <- read.csv('~/Documents/GitHub/forecasting_2/Data/sell_prices.csv', stringsAsFactors = FALSE)
prices_TX1 <- prices
# Subset to a specific store
TXdf <- subset(df, store_id == "TX_1")

# Take only the sales columns and transpose them
tdf <- t(TXdf[,7:ncol(TXdf)])

# Add "NA" values for the validation days;
# Could also drop the extra columns from from `cal`
tdf2 <- rbind(tdf, 
              matrix(NA, nrow = nrow(cal) - nrow(tdf),
                     ncol = ncol(tdf)))
tdf3 <- data.frame(cbind(cal, tdf2))

# Add in the unique names for each column
colnames(tdf3) <- c(colnames(tdf3)[1:14], TXdf$id)

# Add price information: 
# 1) Reshape the price data to have time series in rows, not columns
# 2) Since the prices are given per week, repeat them accordingly to 
#    get a full time series
# 3) For those prices which are absent at the beginning of the data,
#    we fill the missing values with the first observed price.

# 1)
prices <- subset(prices, store_id == "TX_1") %>% select(-store_id,) %>%
  spread(item_id, sell_price)
colnames(prices) <- c("wm_yr_wk", paste0("PRICE_", colnames(prices)[-1]))

# 2)
repetitions <- table(tdf3$wm_yr_wk)
prices_full <- data.frame(wm_yr_wk = rep(prices$wm_yr_wk, times = repetitions))
for (j in 2:ncol(prices))
  prices_full <- cbind(prices_full, rep(prices[,j], times = repetitions))
colnames(prices_full) <- colnames(prices)

# 3)
are_na_at_beginning <- is.na(prices_full[1,])
for (j in which(are_na_at_beginning)) {
  first_non_na <- which(!is.na(prices_full[,j]))[1]
  prices_full[1:first_non_na,j] <- prices_full[first_non_na, j]
}

# Finally, combine all the data (volume + calendar + prices)
tdf4 <- merge(tdf3, prices_full, by = "wm_yr_wk")

```


## Organisation of stores

#### Sales of each state

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
df$Sales_per_product <- df %>% select(7:1919) %>% mutate() %>% rowSums()

u <- df %>%
  group_by(state_id) %>%
  mutate(sales_state = sum(Sales_per_product, na.rm = T)) %>%
  ungroup() %>%
  mutate(total_sales = sum(Sales_per_product)) %>%
  mutate(pour_sales_state = sales_state/total_sales)

u %>% 
  distinct(state_id, pour_sales_state) %>%  
  ggplot() +
  geom_col( aes(state_id, pour_sales_state, fill = state_id)) +
  theme_bw() +
  labs(x = "State ID", y = "Proportion of sales", size = 10) +
  labs(title = "Proportion of sales by state") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 10)) +
  theme(legend.position = "None") +
  scale_fill_manual(values = c("#69b3a2","steelblue3", "#69b3a2"))

remove(u)
```

We can see that CA represents more than 40% of sales, while WI and TX are about the same.

#### Sales by store

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

i <- df %>%
  group_by(store_id) %>%
  mutate(sales_store = sum(Sales_per_product, na.rm = T))

i %>% 
  distinct(store_id, sales_store) %>%  
  ggplot() +
  geom_col( aes(store_id, sales_store, fill = store_id)) +
  theme_bw() +
  labs(x = "Store ID", y = "Total sales", size = 10) +
  labs(title = "Total sales by store") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 10)) +
  theme(legend.position = "None") +
  scale_fill_manual(values =c("#69b3a2", "#69b3a2", "#69b3a2",  "#69b3a2","steelblue3", "#69b3a2", "#69b3a2", "#69b3a2", "#69b3a2", "#69b3a2"))

#remove(i)#69b3a2", "#404080"
```

We can see that the two stores with the most sales are in CA, which is not surprising given the previous plot. Our store, TX_1 is more or less in the average in terms of sales. 

Now, let's focus on our store, TX_1

#### Sales by category

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
TXdf$Sales_per_product <- TXdf %>% select(7:1919) %>% mutate() %>% rowSums()

w <- TXdf%>%
  group_by(cat_id)%>%
  mutate(sum_sales = sum(Sales_per_product)) %>%
  ungroup() %>%
  mutate(total_sales = sum(Sales_per_product)) %>%
  mutate(sales_cat = sum_sales/total_sales)

w %>%
  distinct(cat_id, sales_cat) %>%
  ggplot() +
  geom_col( aes(cat_id, sales_cat), fill = "steelblue3") +
  theme_bw() +
  labs(x = "category ID", y = "Proportion of sales", size = 10) +
  labs(title = "Proportion of sales by category") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 10)) +
  theme(legend.position = "None")

remove(w)
```

We can see that food represents the vast majority of sales with more than 60%, followed by household. Hobbies represent less than 10% of sales.


#### Sales by department

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
q <- TXdf%>%
  group_by(dept_id)%>%
  mutate(sum_sales = sum(Sales_per_product)) %>%
  ungroup() %>%
  mutate(total_sales = sum(Sales_per_product)) %>%
  mutate(sales_dept = sum_sales/total_sales)

q %>%
  distinct(dept_id, sales_dept) %>%
  ggplot() +
  geom_col( aes(dept_id, sales_dept), fill = "steelblue3") +
  theme_bw() +
  labs(x = "departement ID", y = "Proportion of sales", size = 10) +
  labs(title = "Proportion of sales by departement") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 10)) +
  theme(legend.position = "None")

remove(q)
```

Not surprisingly, this is one of the food departments that accounts for the vast majority of sales. Household_1 accounts for most of the sales of the household department.

## Sales

#### Sales by day of the week

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
tdf3$Sales_per_day <- tdf3 %>% select(15:3063) %>% mutate() %>% rowSums()

e <- tdf3 %>%
  group_by(weekday) %>%
  mutate(sales_weekday = mean(Sales_per_day, na.rm = T)) 

e <- e %>% distinct(weekday, sales_weekday) 

e$weekday <- ordered(e$weekday, levels=c("Monday", "Tuesday", "Wednesday", "Thursday", 
"Friday", "Saturday", "Sunday"))

ggplot(e) +
  geom_col(aes(weekday, sales_weekday), fill = "steelblue3") +
  theme_bw() +
  labs(x = "Weekday", y = "Average sales", size = 10)+labs(title = "Average sales per weekday") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 10)) +
  theme(legend.position = "None")

remove(e)
```

We can see that the store make more sales during the weekend.

#### Sales by month

```{r echo=FALSE, message=FALSE, warning=FALSE}
r <- tdf3%>%
  group_by(month)%>%
  mutate(avg_sale_month = mean(Sales_per_day, na.rm = T))
  
ggplot(r)+
  geom_col(aes(x = as.factor(month), y = avg_sale_month), fill = "steelblue3") +
  theme_bw() +
  labs(x = "Month", y = "Average sales", size = 10) +
  labs(title = "Average sales per month") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 10)) +
  theme(legend.position = "None")+
  scale_x_discrete(labels = c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")) +
  theme(axis.text.x = element_text(size = 8, angle = 10))
  
remove(r)
```

It seems that sales are slightly higher between February and June and lower between November and January.


#### Are the sales similar if you compare the years ?

```{r echo=FALSE, message=FALSE, warning=FALSE}

t <-tdf3 %>%
  group_by(month, year) %>%
  mutate(sales_season = sum(Sales_per_day, na.rm = T)) %>%
  distinct(month, year, sales_season)

t <- t %>%
  ungroup()

t.ts <- ts(t, start = c(2011, 1), end = c(2016,6), frequency = 12)

t.ts <- t.ts[,c(3)]

ggseasonplot(t.ts) + 
  labs(title = "seasonplot of sales")

remove(t)
```


All years seem similar, with slightly lower sales at the beginning and end of the year and higher sales between May and September. Sales are exceptionally high in July 2015.
Note that not all products were on sale from January 2011, which is probably why 2011 does not follow the seasonality before August. 

## Prices

#### Price evolution in categories

```{r echo=FALSE, message=FALSE, warning=FALSE}
prices_TX1 <- prices_TX1 %>% dplyr::filter(prices_TX1$store_id == "TX_1")


prices_TX1 %>%
  mutate(category = substr(item_id, 1, 5)) %>%
  group_by(category, wm_yr_wk) %>%
  mutate(avg_price = mean(sell_price)) %>%
  ggplot() +
  geom_line(aes(wm_yr_wk, avg_price, color = category)) +
  labs(x = "weeks", y = "average prices", size = 10)+
  labs(title = "Evolution of prices over time by category")
```

this plot is to see if there seems to be a trend in the applied prices. Average prices are lower at the beginning, but this is probably because not all products were sold by 2011. 

In this case there doesn't seem to be any particular trend.

#### Price evolution of one product over time

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#price evolution for one product in particular
prices %>%
  select(wm_yr_wk, PRICE_FOODS_3_794) %>% 
  ggplot(aes(wm_yr_wk, PRICE_FOODS_3_794)) +
  geom_line() +
  theme_bw() +
  labs(x = "weeks", y = "price", size = 10) +
  labs(title = "FOODS_3_794")
```

We have selected product "FOODS_3_794 in particular to show the possible price variations over time. The three downward peaks are probably discounts or an error in the data.




## Calendar

#### list of event type

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
events <- cal[!is.na(cal$event_type_1), ]   

events %>%
  count(event_type_1) %>%
  ggplot() +
  geom_col(aes(event_type_1, n), fill = "steelblue3") +
  theme_bw() +
  scale_y_discrete(limits = c(10,20,30,40,50)) +
  labs(x = "Event type", y = "", title = "Proportion of events by type ?")

```

there's a majority of national and religious events. But it would be interesting to know what events there are in particular during the 28 days that we have to predict. 

#### Historical events within the 28-day prediction period

if you look manually, the only events that take place during the 28 days to be predicted are: "NBA Finals", "Independence day", "Ramadan start" and "Father's day". In 2016, within that time frame, there was only Independence Day, which took place

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
lm(Sales_per_day~event_name_1 == "IndependenceDay", tdf3) %>%
  broom::tidy()%>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
```

We can see that Independence Day does not have a significant impact on sales. 