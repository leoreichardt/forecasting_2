---
title: "Appendix ARIMA"
author: "Raffaello Raffin"
date: "5/24/2020"
output: html_document
---

```{r include=FALSE}
#set some options for the chunks
knitr::opts_chunk$set(
  fig.align = 'center'
)
```

```{r include=FALSE}
library(readr)
library(hts)
library(stringi)
library(dplyr)
library(stringr)
library(purrr)
library(tidyr)
library(ggplot2)
library(ggpubr)
library(gridExtra)
library(kableExtra)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Load data
df <- read_csv("~/Documents/GitHub/forecasting_2/Data/sales_train_validation.csv")
df <- data.frame(df, stringsAsFactors = FALSE)
df <- within(df, 
             item_id <- as.factor(item_id),
             dept_id <- as.factor(dept_id),
             cat_id <- as.factor(cat_id))
cal <- read.csv("~/Documents/GitHub/forecasting_2/Data/calendar.csv", na.strings = "")
prices <- read_csv("~/Documents/GitHub/forecasting_2/Data/sell_prices.csv")
prices <- data.frame(prices, stringsAsFactors = FALSE)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Subset to a specific store
df <- subset(df, store_id == "TX_1")
 
# Take only the sales columns and transpose them
tdf <- t(df[,7:ncol(df)])

# Add "NA" values for the validation days;
# Could also drop the extra columns from from `cal`
tdf2 <- rbind(tdf, 
              matrix(NA, nrow = nrow(cal) - nrow(tdf),
                     ncol = ncol(tdf)))
tdf3 <- data.frame(cbind(cal, tdf2))

# Add in the unique names for each column
colnames(tdf3) <- c(colnames(tdf3)[1:14], df$id)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Add price information: 
# 1) Reshape the price data to have time series in rows, not columns
# 2) Since the prices are given per week, repeat them accordingly to 
#    get a full time series
# 3) For those prices which are absent at the beginning of the data,
#    we fill the missing values with the first observed price.

# 1)
prices <- subset(prices, store_id == "TX_1") %>% select(-store_id,) %>%
  spread(item_id, sell_price)
colnames(prices) <- c("wm_yr_wk", paste0("PRICE_", colnames(prices)[-1]))

# 2)
repetitions <- table(tdf3$wm_yr_wk)
prices_full <- data.frame(wm_yr_wk = rep(prices$wm_yr_wk, times = repetitions))
for (j in 2:ncol(prices))
  prices_full <- cbind(prices_full, rep(prices[,j], times = repetitions))
colnames(prices_full) <- colnames(prices)

# 3)
are_na_at_beginning <- is.na(prices_full[1,])
for (j in which(are_na_at_beginning)) {
  first_non_na <- which(!is.na(prices_full[,j]))[1]
  prices_full[1:first_non_na,j] <- prices_full[first_non_na, j]
}
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Finally, combine all the data (volume + calendar + prices)
tdf4 <- merge(tdf3, prices_full, by = "wm_yr_wk")
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# In the following, we discard the price part and work only with the volume data.

# When using `hts`, we first need to create a multivariate time series object;
# for this we discard several calendar columns which are redundant.
TX1 <- ts(tdf3[,-(1:14)], frequency = 7)
training_set <- TX1[1:1857,]   ## on a 1913 jours avec data --> enl√®ve 2x 28 (test/validation set)
validation_set <- TX1[1858:1885,]  ## on prend les premiers 28 jours qui serviront de test
validation_set_for_diff <- TX1[1851:1885,] #pour la diff de lag 7
validation_set_for_diff2 <- TX1[1828:1885,]
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Next we have to create a way of denoting which series is nested in another.
# This is done by supplying the `bnames` argument to hts(), and here 
# we create the corresponding names by truncating the category names to 3 letters.

# 1) Separate out the parts in the id column
splitted <- do.call(rbind, stri_split_fixed(df$id, '_'))[,1:5]
# 2) Normalise the category names
splitted[,1] <- substr(splitted[,1], 1, 3)
hts_ids <- apply(splitted, 1, paste0, collapse = '')
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Create the hts object by specifying which parts of the series name correspond
# to which level of the hierarchy
ts_all <- hts(TX1, bnames = hts_ids, characters = c(3,1,6))
training_set <- hts(training_set, bnames = hts_ids, characters = c(3,1,6))
validation_set <- hts(validation_set, bnames = hts_ids, characters = c(3,1,6))
validation_set_for_diff <- hts(validation_set_for_diff, bnames = hts_ids, characters = c(3,1,6))
validation_set_for_diff2 <- hts(validation_set_for_diff2, bnames = hts_ids, characters = c(3,1,6))
```


## ARIMA without hierarchical decomposition

In the exploratory data analysis, we could see that our data had different seasonality. The weekly seasonality was particularly strong. So we decided to create a time series with a frequency of 7 days.  
We tried to fit an Arima model in different ways on TX_1.

```{r message=FALSE, warning=FALSE, include=FALSE}
#take only level 0
train_set <- training_set %>% aggts(levels=0)
val_set <- validation_set %>% aggts(levels=0)
val_set_for_diff <- validation_set_for_diff %>% aggts(levels=0)
val_set_for_diff2 <- validation_set_for_diff2 %>% aggts(levels=0)
```


### Auto.arima with transformation

#### Lag 7 differenciation

We will start by applying a differentiation with a lag 7.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#transformation
diff_train_set <- diff(train_set, lag = 7)

plot(diff_train_set) 

ggAcf(diff_train_set, lag.max = 90) +
  theme_bw() +
  labs(title = "Correlogram",
       subtitle = "Differenciated time series") +
         theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5))
```

We now have a time series centered around zero. Once again, on the time plot, you can see the days that correspond to the closing of the store on Christmas day. On the ACF, on the other hand, we can see that there is still a monthly seasonality (d = 30).

We will now apply an auto.arima and see if we get something better in terms of residues.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#fit model
model_autoB <- diff_train_set %>% auto.arima(approximation = FALSE, stepwise = FALSE)
checkresiduals(model_autoB)
```

This time we have an ARIMA(0,0,1) which shows that it did not apply any additional differentiation. For the residues, we still don't get something satisfactory but the pattern is less clear than before. The Ljung-Box test confirms that the residues of our model do not come from a white noise.

Now let's forecast for the next 28 days and look at the metrics:

```{r echo=FALSE, message=FALSE, warning=FALSE}
#forecast
fcB <- model_autoB %>% forecast(h=28)
fcB <- data.frame(fcB)
fcB <- ts(fcB)

diff_validation_set <- diff(val_set_for_diff, lag = 7)
diff_validation_set <- data.frame(diff_validation_set)
diff_validation_set <- ts(diff_validation_set)

accB <- accuracy(fcB, diff_validation_set)
kableExtra::kable(accB,
    caption = "<center><strong>28 days forcecast accuracy metrics</strong></center>",
    escape = FALSE,
    format = "html")%>%
    kableExtra::kable_styling(
        bootstrap_options = c("striped","bordered"),
        full_width = F)
```

As we differentiated the data before applying our model, we also differentiated the validation set to get the accuracy metrics (being careful to add 7 days before differentiating to keep 28 days). 

Normally, after forecasting, we are supposed to undiff the values but unfortunately we were not able to do so. The results we obtain therefore do not allow us to make any reliable comparison. The graph below is also distorted.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#plot
 autoplot(diff_validation_set) +
  autolayer(fcB, lty=2) +
   theme_bw() +
      labs(title = "Observations & Predictions",
        subtitle = "With confidence interval") +
       theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5))
```


#### Lag 30 differenciation

For the following test, we will take our initial time series, apply a differentiation with a lag of 30 and apply an arima.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#transformation
diff_train_set <- diff(train_set, lag = 30)
plot(diff_train_set)
ggAcf(diff_train_set, lag.max = 90) +
   theme_bw() +
  labs(title = "Correlogram",
       subtitle = "Differenciated time series") +
         theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5))
```

This time, on the ACF, it is the weekly seasonality that appears.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#fit model
model_autoC <- diff_train_set %>% auto.arima(approximation = FALSE, stepwise = FALSE)
checkresiduals(model_autoC)
```

The auto.arima function gives an ARIMA(5,0,0). Again, no further differentiation was applied. As in the previous tests, the Ljung-Box rejects H0 with a p-value lower than 0.05. This is also visible on the ACF. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
#forecast
fcC <- model_autoC %>% forecast(h=28)
fcC <- data.frame(fcC)
fcC <- ts(fcC)

diff_validation_set <- diff(val_set_for_diff2, lag = 30)
diff_validation_set <- data.frame(diff_validation_set)
diff_validation_set <- ts(diff_validation_set)

accC <- accuracy(fcC, diff_validation_set)
kableExtra::kable(accC,
    caption = "<center><strong>28 days forcecast accuracy metrics</strong></center>",
    escape = FALSE,
    format = "html")%>%
    kableExtra::kable_styling(
        bootstrap_options = c("striped","bordered"),
        full_width = F)
```

Here, the remarks are the same than in the previous forecast but with a higher (worse) RMSE. However, since the differentiation applied is not the same, we are not sure that the results are comparable.

On the graph, we have something that follows the data more closely.

```{r echo=FALSE}
#plot
autoplot(diff_validation_set) +
  autolayer(fcC, lty=2) +
   theme_bw() +
     labs(title = "Observations & Predictions",
        subtitle = "With confidence interval") +
       theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5))
```


