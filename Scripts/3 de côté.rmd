---
output: html_document
---




```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(readr)
library(tidyverse)
library(ggseas)
library(hts)
library(dplyr)
library(stringr)
library(purrr)
library(tidyr)
library(here)
library(stringi) 
library(kableExtra)
```

```{r load data, message=FALSE, warning=FALSE, include=FALSE}
# Load data
df <- read_csv("~/Documents/GitHub/forecasting_2/Data/sales_train_validation.csv")
df <- data.frame(df, stringsAsFactors = FALSE)
df <- within(df, 
             item_id <- as.factor(item_id),
             dept_id <- as.factor(dept_id),
             cat_id <- as.factor(cat_id))
cal <- read.csv("~/Documents/GitHub/forecasting_2/Data/calendar.csv", na.strings = "")
prices <- read_csv("~/Documents/GitHub/forecasting_2/Data/sell_prices.csv")
prices <- data.frame(prices, stringsAsFactors = FALSE)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
tdf <- t(df[,7:ncol(df)])

tdf2 <- rbind(tdf, 
              matrix(NA, nrow = nrow(cal) - nrow(tdf),
                     ncol = ncol(tdf)))
tdf3 <- data.frame(cbind(cal, tdf2))

colnames(tdf3) <- c(colnames(tdf3)[1:14], df$id)


tdf3$Christmas <- ifelse(tdf3$event_name_1 == "Christmas", 1,0)
tdf3$Christmas[is.na(tdf3$Christmas)] = 0

tdf3$IndependenceDay <- ifelse(tdf3$event_name_1 == "IndependenceDay", 1,0)
tdf3$IndependenceDay[is.na(tdf3$IndependenceDay)] = 0

tdf3$SuperBowl <- ifelse(tdf3$event_name_1 == "SuperBowl", 1,0)
tdf3$SuperBowl[is.na(tdf3$SuperBowl)] = 0


specialDays_modeling <- cbind(tdf3$IndependenceDay[1:1857],tdf3$SuperBowl[1:1857], tdf3$Christmas[1:1857])
specialDays_forecasting <- cbind(tdf3$IndependenceDay[1858:1885],tdf3$SuperBowl[1858:1885], tdf3$Christmas[1858:1885])
```

# Modeling

## Preparing the data for analysis and general methodology

### Putting our data into a time series

We were looking at two different frequencies: monthly and weekly. 
Each seemed to make sense when we used them to remove seasonality (see EDA).

However, 

So we have 2 frequencies to compare: one of 365 and one of 7.  


### Divide the time series into training/validation/test sets:

To avoid any problem related to the frequency used when creating the time series, we decided to use brackets. 

The data at our disposal contains 1969 days (lines); however, from line 1914, the data is only composed of NA.

We decided to remove 56 days (2x28) from the training set. This allows us to measure the predictions with a validation set of 28 days and still have a test set. 
 

### Choice of the metric 

According to the paper *Another look at measures of forecast accuracy*, using the MASE would ensure us easily applicable metric among our methods. 

Moreover, being the mean absolute error of the forecast values, divided by the mean absolute error of the in-sample one-step naive forecast, it allows us to use it as a benchmark.   
Thus, a MASE with a value higher than one would mean that our model is less attractive than in-sample one-step forecasts from the naive method and thus should not be considered.

Therefore, we use the MASE to evaluate the next forecasts accuracies.


## Hierarchical modeling 

### First tests


Having to analyze the TX1 store, we had started by trying to modelize the sales of this store using all the data. 

We were soon confronted with the problems of the lack of power of our laptops. 

However, we were not sure that the code and method used was the right one and to better understand how the *hts* and *forecast* functions work, we decided to conduct an analysis only on HOBBIES_2 which is the department with the fewest items in the store. 

We only managed to make the following prediction: 
A model using the bottom-up arima method. 

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create the data frame
df_HOBBIES_2 <- subset(df, store_id == "TX_1" & dept_id == "HOBBIES_2")

tdf_HOBBIES_2 <- t(df_HOBBIES_2[,7:ncol(df)])

tdf2_HOBBIES_2 <- rbind(tdf_HOBBIES_2, 
              matrix(NA, nrow = nrow(cal) - nrow(tdf_HOBBIES_2),
                     ncol = ncol(tdf_HOBBIES_2)))
tdf3_HOBBIES_2 <- data.frame(cbind(cal, tdf2_HOBBIES_2))

colnames(tdf3_HOBBIES_2) <- c(colnames(tdf3_HOBBIES_2)[1:14], df_HOBBIES_2$id)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create times series and divide it into training / validation set
TS_HOBBIES_2 <- ts(tdf3_HOBBIES_2[,-(1:14)], frequency = 7)
TS_HOBBIES_2_tr <- TS_HOBBIES_2[1:1857,]
TS_HOBBIES_2_val <- TS_HOBBIES_2[1858:1885,]
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create bnames 
splitted <- do.call(rbind, stri_split_fixed(df_HOBBIES_2$id, '_'))[,1:5]
splitted[,1] <- substr(splitted[,1], 1, 3)
hts_ids <- apply(splitted, 1, paste0, collapse = '')
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create HTS with the 2 hierarchical levels : dept_id / each articles
HTS_HOBBIES_2_tr <- hts(TS_HOBBIES_2_tr, bnames = hts_ids, characters = c(4,6))
HTS_HOBBIES_2_val <- hts(TS_HOBBIES_2_val, bnames = hts_ids, characters = c(4,6))
```
**Top level : Hobbies_2**    
**Bottom level : all items**  
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# forecast using arima bu approach
FORECAST_HOBBIES_2 <- forecast(HTS_HOBBIES_2_tr, h = 28, method = "bu", fmethod = "arima")
ACC_HOBBIES_2 <- accuracy.gts(FORECAST_HOBBIES_2, HTS_HOBBIES_2_val)
ACC_HOBBIES_2 <- round(ACC_HOBBIES_2, digits = 3)


kableExtra::kable(ACC_HOBBIES_2[, c(2,12,18)], col.names = c("HOBBIES_2", "HOB2010TX1", "HOB2016TX1"),
    caption = "<center><strong> 28 days forcecast : metrics of an ARIMA model</strong></center>",
    escape = FALSE,
    format = "html") %>%
    kableExtra::kable_styling(
        bootstrap_options = c("striped","bordered"),
        full_width = F) %>%
  add_header_above(c(" ", "Bottom-up" = 3)) %>%
  column_spec(1, bold = T) %>%
  column_spec(2:4, width = "8em") %>%
    row_spec(6, background = "lightyellow") 
```

The model is not good, the MASE of HOBBIES_2 is higher than 1, however, using an arima for some articles could be a good option as we can see with the article: HOB2016TX1.But for others the model doesn't work at all. Moreover, the problem remained the same: we won't be able to compute more than 3,000 different models for each item sold at Walmart.
If we had more time we could have taken each item separately to find the best possible model. We probably would have chosen an arima for HOB2016TX1 while we would have looked for another model for HOB2010TX1 before aggregating them all.

### We no longer used the bottom level

In order to analyze all the sales of the store, an analysis stopping at the level of each department is more reasonable. 

Thus we have modified our code to aggregate the sales of each item at the level of their respective department.

We computed 5 different models two with a bottom-up and top-down approach (ARIMA Model and Exponential Smoothing State Space Model).
We add to the ARIMA model with bottom-up approach regressors corresponding to Christmas and Independance day.



```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create the data frame
df_TX1 <- subset(df, store_id == "TX_1")

tdf_TX1 <- t(df_TX1[,7:ncol(df_TX1)])

tdf2_TX1 <- rbind(tdf_TX1, 
              matrix(NA, nrow = nrow(cal) - nrow(tdf_TX1),
                     ncol = ncol(tdf_TX1)))
tdf3_TX1 <- data.frame(cbind(cal, tdf2_TX1))

colnames(tdf3_TX1) <- c(colnames(tdf3_TX1)[1:14], df_TX1)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create time series training / validation test
TS_TX1 <- ts(tdf3_TX1[,-(1:14)], frequency = 7)
TS_TX1_tr <- TS_TX1[1:1857,]
TS_TX1_val <- TS_TX1[1858:1885,]
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# which series are nested in another.
splitted <- do.call(rbind, stri_split_fixed(df_TX1$id, '_'))[,1:5]
splitted[,1] <- substr(splitted[,1], 1, 3)
hts_ids <- apply(splitted, 1, paste0, collapse = '')
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create hts objects
HTS_TX1_tr <- hts(TS_TX1_tr, bnames = hts_ids, characters = c(3,1,6))
HTS_TX1_val <- hts(TS_TX1_val, bnames = hts_ids, characters = c(3,1,6))
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# do not analyse article level
TS_TX1_tr <- HTS_TX1_tr %>% aggts(levels=0:2) # do not take into consideration level 3
TS_TX1_val <- HTS_TX1_val %>% aggts(levels=0:2)

#put back in hts object
hts_ids_lvl_0_to_2 <- str_sub(hts_ids, end = 4) %>% unique() # get the bname without articles


HTS_TX1_tr <- hts(TS_TX1_tr, bnames = hts_ids_lvl_0_to_2, characters = c(3,1))
HTS_TX1_val <- hts(TS_TX1_val, bnames = hts_ids_lvl_0_to_2, characters = c(3,1))
```
**Top level : TX1**  
**Bottom level : dept_id**  
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
FORECAST_TX1_bu_arima <- forecast(HTS_TX1_tr, h = 28, method = "bu", fmethod = "arima", xreg = specialDays_modeling, newxreg = specialDays_forecasting)
ACC_TX1_bu_arima <- accuracy.gts(FORECAST_TX1_bu_arima, HTS_TX1_val) # RMSE = 1349.81 --> 1228.32

FORECAST_TX1_bu_ets <- forecast(HTS_TX1_tr,h =28, method = "bu", fmethod = "ets")
ACC_TX1_bu_ets <- accuracy.gts(FORECAST_TX1_bu_ets, HTS_TX1_val)  #RMSE = 1508.707
#-------------------   ATTENTION ----------------
FORECAST_TX1_tdfp_arima <- forecast(HTS_TX1_tr,h =28, method = "tdfp", fmethod = "arima", xreg = specialDays_modeling, newxreg = specialDays_forecasting)
ACC_TX1_tdfp_arima <- accuracy.gts(FORECAST_TX1_tdfp_arima, HTS_TX1_val)  #RMSE = 1360.54 --> 1460
#-------------------   ATTENTION ----------------

FORECAST_TX1_tdfp_ets <- forecast(HTS_TX1_tr,h =28, method = "tdfp", fmethod = "ets")
ACC_TX1_tdfp_ets <- accuracy.gts(FORECAST_TX1_tdfp_ets, HTS_TX1_val)  #RMSE = 1514.346

FORECAST_TX1_comb <- forecast(HTS_TX1_tr,h =28, method = "comb", weights = "mint", covariance = "shr", xreg = specialDays_modeling, newxreg = specialDays_forecasting)
ACC_TX1_bu_comb <- accuracy.gts(FORECAST_TX1_comb, HTS_TX1_val)  #RMSE = 1502.121

ACC <- data.frame(ACC_TX1_bu_arima, ACC_TX1_bu_ets, ACC_TX1_tdfp_arima, ACC_TX1_tdfp_ets, ACC_TX1_bu_comb)
ACC <- round(ACC, digits = 3)

kableExtra::kable(ACC[, c(1,12,23,34,45)], col.names = c("ARIMA", "ETS", "ARIMA", "ETS", "mint - shr"),
    caption = "<center><strong> 28 days forcecast : metrics of different models</strong></center>",
    escape = FALSE,
    format = "html") %>%
    kableExtra::kable_styling(
        bootstrap_options = c("striped","bordered"),
        full_width = F) %>%
  add_header_above(c(" ", "Bottom-up" = 2, "Top-down" = 2, "Comb" = 1)) %>%
  column_spec(1, bold = T) %>%
  column_spec(2:6, width = "8em") %>%
row_spec(6, background = "lightyellow")


```

The ARIMA model using a bottom-up approach gives the best results.


### Let's use the levels above

We realized using the top-down method before, that by limiting the top level to TX1 we were losing information that could be taken into account.
Furthermore, using all the stores in Texas as well as all the stores in the US would not add so much extra model to compute for the computer.

Thus we have re-tried the models used previously.

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create the data frames

tdf <- t(df[,7:ncol(df)])

tdf2 <- rbind(tdf, 
              matrix(NA, nrow = nrow(cal) - nrow(tdf),
                     ncol = ncol(tdf)))
tdf3 <- data.frame(cbind(cal, tdf2))

colnames(tdf3) <- c(colnames(tdf3)[1:14], df$id)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create hts objects
TS_ALL <- ts(tdf3[,-(1:14)], frequency = 7)
TS_tr <- TS_ALL[1:1857,]   ## on a 1913 jours avec data --> enlève 2x 28 (test/validation set)
TS_val <- TS_ALL[1858:1885,]  ## on prend les premiers 28 jours qui serviront de test
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# which series are nested in another.
splitted <- do.call(rbind, stri_split_fixed(df$id, '_'))[,1:5]
splitted[,1] <- substr(splitted[,1], 1, 3)
# Arrange the order to have the State in first position
splitted <- splitted[, c(4,5,1,2,3)]

hts_ids <- apply(splitted, 1, paste0, collapse = '')
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# create hts object
HTS_tr <- hts(TS_tr, bnames = hts_ids, characters = c(2,1,3,1,3))
HTS_val <- hts(TS_val, bnames = hts_ids, characters = c(2,1,3,1,3))
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# remove level with single item

lvl_0_to_4_tr <- HTS_tr %>% aggts(levels=0:4) # aggregate the articles
lvl_0_to_4_val <- HTS_val %>% aggts(levels=0:4)

hts_ids_lvl_0_to_4 <- str_sub(hts_ids, end = 7) %>% unique() # get the name without articles

# This gives the hts with top level = state, lower level = HOB1 (category)
HTS_tr_lvl_0_to_4 <- hts(lvl_0_to_4_tr, bnames = hts_ids_lvl_0_to_4, characters = c(2,1,3,1))
HTS_te_lvl_0_to_4 <- hts(lvl_0_to_4_val, bnames = hts_ids_lvl_0_to_4, characters = c(2,1,3,1))
```
**Top level : all stores**  
**Bottom level : dept_id**
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# bu
FORECAST_ALL_bu_arima <- forecast(HTS_tr_lvl_0_to_4, h = 28, method = "bu", fmethod = "arima", xreg = specialDays_modeling, newxreg = specialDays_forecasting)
ACC_ALL_bu_arima <- accuracy.gts(FORECAST_ALL_bu_arima, HTS_te_lvl_0_to_4)   ## We get RMSE of TX1 = 927.4927684 --> 919.52

FORECAST_ALL_bu_ets <- forecast(HTS_tr_lvl_0_to_4, h = 28, method = "bu", fmethod = "ets")
ACC_ALL_bu_ets <- accuracy.gts(FORECAST_ALL_bu_ets, HTS_te_lvl_0_to_4)   ## We get RMSE of TX1 = 1072.45
#------------------------

# tdfp
FORECAST_ALL_tdfp_arima <- forecast(HTS_tr_lvl_0_to_4, h = 28, method = "tdfp", fmethod = "arima")
ACC_ALL_tdfp_arima <- accuracy.gts(FORECAST_ALL_tdfp_arima, HTS_te_lvl_0_to_4)   ## We get RMSE of TX1 = 959.829

FORECAST_ALL_tdfp_ets <- forecast(HTS_tr_lvl_0_to_4, h = 28, method = "tdfp", fmethod = "ets")
ACC_ALL_tdfp_ets <- accuracy.gts(FORECAST_ALL_tdfp_ets, HTS_te_lvl_0_to_4)   ## We get RMSE of TX1 = 1681.50
#------------------------
#comb
FORECAST_ALL_comb_arima <- forecast(HTS_tr_lvl_0_to_4, h =28, method = "comb", weights = "mint", covariance = "shr" )
ACC_ALL_mo_arima <- accuracy.gts(FORECAST_ALL_comb_arima, HTS_te_lvl_0_to_4)   ## We get RMSE of TX1 = 1273.73


ACC2 <- data.frame(ACC_ALL_bu_arima, ACC_ALL_bu_ets, ACC_ALL_tdfp_arima, ACC_ALL_tdfp_ets, ACC_ALL_mo_arima)
ACC2 <- round(ACC2, digits = 3)

kableExtra::kable(ACC2[, c(9,123,237,351,465)],  col.names = c("ARIMA", "ETS", "ARIMA", "ETS", "mint - shr"),
    caption = "<center><strong>28 days forcecast accuracy: metrics of different models</strong></center>",
    escape = FALSE,
    format = "html")%>%
    kableExtra::kable_styling(
        bootstrap_options = c("striped","bordered"),
        full_width = F) %>%
  add_header_above(c(" ", "Bottom-up" = 2, "Top-down" = 2, "Comb" = 1)) %>%
  column_spec(1, bold = T) %>%
  column_spec(2:6, width = "8em") %>%
row_spec(6, background = "lightyellow")


```


These models give better results.

We had omitted an option that seemed to make no sense until then: the middle out.
Indeed, combining a bottom-up method going from departments to TX1 stores and a top-down method going from all stores in the US to TX1 stores seemed promising.

**Top level : all stores**  
**Bottom level : dept_id**  
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# mo
FORECAST_ALL_mo_arima <- forecast(HTS_tr_lvl_0_to_4, h =28, method = "mo", level = 2, fmethod = "arima")
ACC_ALL_mo_arima <- accuracy.gts(FORECAST_ALL_mo_arima, HTS_te_lvl_0_to_4)   ## We get RMSE of TX1 = 914.79 

FORECAST_ALL_mo_ets <- forecast(HTS_tr_lvl_0_to_4, h =28, method = "mo", level = 2, fmethod = "ets" )
ACC_ALL_mo_ets <- accuracy.gts(FORECAST_ALL_mo_ets, HTS_te_lvl_0_to_4)   ## We get RMSE of TX1 = 1081.34


ACC_ALL <- data.frame(ACC_ALL_mo_arima, ACC_ALL_mo_ets)
ACC_ALL <- round(ACC_ALL, digits = 3)

### MAUVAISE COLONES
kableExtra::kable(ACC_ALL[, c(9,123)], col.names = c("ARIMA", "ETS"), 
    caption = "<center><strong>28 days forcecast accuracy: metrics of the models</strong></center>",
    escape = FALSE,
    format = "html") %>%
    kableExtra::kable_styling(
        bootstrap_options = c("striped","bordered"),
        full_width = F) %>%
  add_header_above(c(" ", "Middle-out" = 2)) %>%
  column_spec(1, bold = T) %>%
  column_spec(2:3, width = "8em") %>%
row_spec(6, background = "lightyellow")

```

```{r}
FORECAST_ALL_bu_arima %>% aggts(levels = 2)
plot(FORECAST_ALL_mo_arima, levels = 2, )
```


Indeed, this was the method that gave us the lowest MASE.


# Forecast accuracy

This is the graph of the validation days with the model in traitillé 
comment me please

```{r}

lowest <-aggts(FORECAST_ALL_bu_arima, levels = 4)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
forecast.hts.bu <- function(object,
                            h,
                            models_lower,
                            B = 1e3)
{
  S <- smatrix(object)
  sims <- array(NA, dim = c(h, ncol(object$bts), B))
  dimnames(sims) <- list(1:h, colnames(object$bts), 1:B)
  for (b in 1:B) {
    sims[, , b] <-
      do.call(cbind, lapply(models_lower, simulate, nsim = h))
  }
  all_sims <- propagate_forecast(sims, S)
  return(sims_to_forecast(all_sims))
  
}


#------

propagate_forecast <- function(base_forecasts, S) {
  aperm(plyr::aaply(base_forecasts, 3, function(u) u %*% t(S)),
        c(2, 3, 1))
}

#---


sims_to_forecast <- function(sims, p = c(0.025, 0.975)) {
  quantiles <- aperm(apply(sims, 1:2, quantile, p), c(2, 3, 1))
  means <- apply(sims, 1:2, mean)
  return(list(
    lower = quantiles[, , 1],
    mean = means,
    upper = quantiles[, , 2]
  ))
}

```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
fc.pr <-
  forecast.hts.bu(FORECAST_ALL_bu_arima,
                  h = 28,
                  models_lower = lapply(lowest + 1, auto.arima, lambda = 0))
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
fc.series <- ts(
  cbind(
    mean = fc.pr$mean[, 9],   # le [, 1] est là pour désigner le level 0 --> nous on veut le lvl 2 c'est la 9ème colonne
    lower = fc.pr$lower[, 9],
    upper = fc.pr$upper[, 9]
  ),
  start = tsp(FORECAST_TX1_bu_arima$bts)[2] + 1, # update the forecast start time
  frequency = tsp(FORECAST_TX1_bu_arima$bts)[3] # copy the frequency
)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
TX1_validation <- aggts(HTS_te_lvl_0_to_4, levels = 2)

fc.series <- data.frame(fc.series)
fc.series <- ts(fc.series)

 autoplot(TX1_validation[,5]) +
  autolayer(fc.series, lty=2)+
   theme_bw() +
      labs(title = "Observations & Predictions",
        subtitle = "With confidence interval",
        y = "Sales",
        x = "Days") +
       theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5)) 


```




